{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import SimpleRNN, LSTM\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the data directory\n",
    "def findFiles(path): \n",
    "    return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return lines\n",
    "\n",
    "def load_data(categories=None):\n",
    "    names_list = []\n",
    "    for filename in findFiles('data/names/*.txt'):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        if not categories or category in categories: \n",
    "            names = readLines(filename)\n",
    "            names_list.extend([(name,category) for name in names])\n",
    "    df = pd.DataFrame(names_list)\n",
    "    df.columns = [\"name\",\"lang\"]\n",
    "    return df\n",
    "    \n",
    "\n",
    "languages = [\"English\",\"French\",\"Italian\",\"German\",\"Spanish\"]\n",
    "names = load_data(languages)\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxlen = np.max([len(name) for name in names.name])\n",
    "print(\"Maximum name length: \", maxlen)\n",
    "names.groupby('lang')['name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphabet\n",
    "\n",
    "Extract from the list of names all the characters occurring. This gives the basis for constructing a vector space representation of the characters by one-hot-vectors.\n",
    "\n",
    "Foresee a suitable character for the end of the word, e.g. 'END'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "alphabet = \n",
    "...\n",
    "\n",
    "### END YOUR CODE\n",
    "alphabet.append('-') # added for later purpose\n",
    "len_alphabet = len(alphabet)\n",
    "char_index = dict((c, i) for i, c in enumerate(alphabet))\n",
    "print(\"Size of alphabet: \",len_alphabet)\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_to_index = {country:index for index,country in enumerate(names.lang.unique())}\n",
    "index_to_language = {index:country for index,country in enumerate(names.lang.unique())}\n",
    "\n",
    "def onehot(i, length):\n",
    "    v = np.zeros(length);\n",
    "    v[i] = 1\n",
    "    return v\n",
    "\n",
    "def name_representation(name, maxlen, char_index):\n",
    "    '''\n",
    "    Create a vector representation for the given name. A list of length maxlen, each element being a \n",
    "    numpy array of lenght len_vocab. \n",
    "    \n",
    "    Parameters:\n",
    "    maxlen: lenght of the list\n",
    "    char_index: dict that returns the index for a given character\n",
    "    '''\n",
    "    ### START YOUR CODE\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### START YOUR CODE\n",
    "    return vector\n",
    "\n",
    "def lang_representation(language, language_to_index):\n",
    "    y = np.zeros(len(language_to_index))\n",
    "    y[language_to_index[language]]=1\n",
    "    return y\n",
    "\n",
    "def lang_from_output(score):\n",
    "    return index_to_language[np.argmax(score)]\n",
    "\n",
    "def predict(name, model):\n",
    "    score = model.predict(np.array([name_representation(name, maxlen,char_index)]))[0]\n",
    "    return lang_from_output(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lang_representation(\"French\",language_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(names)) < 0.8\n",
    "train = names[msk]\n",
    "test = names[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for name in train.name:\n",
    "    X_train.append(name_representation(name,maxlen,char_index))\n",
    "for lang in train.lang:\n",
    "    Y_train.append(lang_representation(lang, language_to_index))\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "print(X_train.shape,Y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "for name in test.name:\n",
    "    X_test.append(name_representation(name,maxlen,char_index))\n",
    "for lang in test.lang:\n",
    "    Y_test.append(lang_representation(lang, language_to_index))\n",
    "        \n",
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)\n",
    "print(X_test.shape,Y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train the Model\n",
    "\n",
    "Create an RNN consisting of a single layer with a SimpleRNN (keras) and a softmax.\n",
    "\n",
    "Then train the model. Play with different number of hidden units in the layer to obtain a good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "n_languages = \n",
    "n_hidden = \n",
    "\n",
    "model = \n",
    "model.add(SimpleRNN(...))\n",
    "...\n",
    "\n",
    "### END YOUR CODE\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "...\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(X_test, Y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log.history['acc'], label='Training')\n",
    "plt.plot(log.history['val_acc'], label='Testing')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some additional outputs: Classify the last names of all the students and teaching personal in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_samples = pd.read_csv(\"stud_names.csv\")\n",
    "df_samples.columns=[\"First\",\"Last\"]\n",
    "#pred_langs = [predict(unicodeToAscii(name), model) for name in df_samples.Last]\n",
    "pred_langs = [predict(name, model) for name in df_samples.Last]\n",
    "df_samples[\"pred0\"] = pred_langs\n",
    "df_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "Compute the confusion matrix and jduge for which languages the names are hard to classify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### START YOUR CODE\n",
    "...\n",
    "\n",
    "cm = \n",
    "### END YOUR CODE\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + languages, rotation=90)\n",
    "ax.set_yticklabels([''] + languages)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
