{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "\n",
    "Binary classification based on MNIST data - classifying whether a given image contains the digit '5' or not.\n",
    "A smaller ('lightweight') version of MNIST is used - containing 8x8 images that are included in the scikit-learn library.\n",
    "\n",
    "In the following, we use the following notation (see also the notations sheet):\n",
    "\n",
    "m: Number of samples <br>\n",
    "n: Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "#### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n",
      "[[ 0.  0.  1.  8. 15. 10.  0.  0.]\n",
      " [ 0.  3. 13. 15. 14. 14.  0.  0.]\n",
      " [ 0.  5. 10.  0. 10. 12.  0.  0.]\n",
      " [ 0.  0.  3.  5. 15. 10.  2.  0.]\n",
      " [ 0.  0. 16. 16. 16. 16. 12.  0.]\n",
      " [ 0.  1.  8. 12. 14.  8.  3.  0.]\n",
      " [ 0.  0.  0. 10. 13.  0.  0.  0.]\n",
      " [ 0.  0.  0. 11.  9.  0.  0.  0.]]\n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "x = digits.data\n",
    "y = digits.target\n",
    "print(\"Image Data Shape\" , x.shape)\n",
    "print(\"Label Data Shape\", y.shape)\n",
    "\n",
    "image = x[17,:]\n",
    "plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "print(np.reshape(image, (8,8)))\n",
    "print(y[17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data and bring it in the correct shape\n",
    "\n",
    "Split the data into training set and test set.\n",
    "We use the scikit-learn function 'train_test_split' and use a (80%/20%) splitting.\n",
    "\n",
    "Furthermore, we bring the input data (x) into the shape (n,m) where n is the number of input features and m the number of samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training set:  (64, 1437) (1, 1437)\n",
      "Shape test set:      (64, 360) (1, 360)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split\n",
    "x_train0, x_test0, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# reshape: \n",
    "# for x a simple transpose is sufficient \n",
    "# (m,n) -> (n,m) where m is the number of samples and n the number of input features (pixels)\n",
    "# for y reshape the simple array to become a (1,m) array\n",
    "x_train1 = x_train0.T\n",
    "x_test1 = x_test0.T\n",
    "m_train = x_train0.shape[0]\n",
    "m_test = x_test0.shape[0]\n",
    "y_train=y_train.reshape(1,m_train)\n",
    "y_test=y_test.reshape(1,m_test)\n",
    "\n",
    "print(\"Shape training set: \", x_train1.shape, y_train.shape)\n",
    "print(\"Shape test set:     \", x_test1.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Normalisation\n",
    "\n",
    "Rescale the data - apply min/max rescaling (- we get back to centering later).\n",
    "\n",
    "Test that the result is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 16.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "xmax = np.max(x_train1)\n",
    "xmin = np.min(x_train1)\n",
    "print(xmin, xmax)\n",
    "x_train = x_train1 / xmax\n",
    "x_test = x_test1 / xmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    ### START YOUR CODE ###\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "    ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(w, b, X, round=False):\n",
    "    '''\n",
    "    Compute the prediction for each of the m samples by using the parameters (w, b).\n",
    "    Return the numeric value if `round=False` - return a rounded value (0 or 1) if `round=True`. \n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array with shape (1, n)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (n,m)\n",
    "    round -- flag to indicate whether to round or not.\n",
    "    \n",
    "    Returns:\n",
    "    predictions -- a numpy array (vector) containing all predictions\n",
    "    ''' \n",
    "    ### START YOUR CODE ###\n",
    "    #y = np.dot(w, X) + b\n",
    "    y = sigmoid(np.dot(w, X) + b)\n",
    "    \n",
    "    if round:\n",
    "        y[y>=0] = 1.\n",
    "        y[y<0] = 0.\n",
    "        return y\n",
    "    return y\n",
    "    ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "* Cross-Entropy Cost Function\n",
    "* Mean Square Error Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapey(yhat,y):\n",
    "    \"\"\"\n",
    "    Checks whether the inputs come as a list in which case it reshapes it to (1,m).\n",
    "    Implementation is sloppy...\n",
    "    \"\"\"\n",
    "    if type(yhat).__module__ == np.__name__:\n",
    "        m = yhat.size\n",
    "        yhat = yhat.reshape(1,m)\n",
    "        y = y.reshape(1,m)\n",
    "    else:\n",
    "        m = 1\n",
    "    return yhat, y, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cost_CE(yhat, y):\n",
    "    \"\"\"\n",
    "    Computes the cross entropy cost function for given predicted values and labels.\n",
    "    \n",
    "    Parameters:\n",
    "    yhat -- A scalar or numpy array with shape (1,m).\n",
    "    y    -- A scalar or numpy array with shape (1,m).\n",
    "    \n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    yhat, y, m = reshapey(yhat, y)\n",
    "    cost = -(1 / m) * np.sum(y * np.log(yhat) + (1-y)*np.log(1 - yhat))\n",
    "    #cost = 0\n",
    "    #for i in range(0, m-1):\n",
    "    #    cost = cost + (y[0][i] * np.log(sigmoid(yhat[0][i])) + (1-y[0][i]) * np.log(1-sigmoid(yhat[0][i])))\n",
    "    return cost\n",
    "    ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cost_MSE(yhat, y):\n",
    "    \"\"\"\n",
    "    Computes the mean square error cost function for given predicted values and labels.\n",
    "    \n",
    "    Parameters:\n",
    "    yhat -- A scalar or numpy array with shape (1,m).\n",
    "    y    -- A scalar or numpy array with shape (1,m).\n",
    "    \n",
    "    Returns:\n",
    "    MSE Cost\n",
    "    \"\"\"    \n",
    "    yhat, y, m = reshapey(yhat, y)\n",
    "\n",
    "    ### START YOUR CODE ###\n",
    "    cost = 1 / (2*m) * np.sum((yhat - y)**2)\n",
    "    \n",
    "    return cost\n",
    "    ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Rules for the Parameters\n",
    "\n",
    "Different update rules associated with the different cost functions.\n",
    "\n",
    "![title](img/ce_update_rule.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def step_CE(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Computes the update of the weights and bias - by using the cross entropy cost. \n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (1,n)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (n, m)\n",
    "    Y -- label vector (1, m)\n",
    "\n",
    "    Returns:\n",
    "    gradJ -- dictionary with the gradient w.r.t. w (key \"dw\") and w.r.t. b (key \"db\")\n",
    "    \"\"\"\n",
    "    ### START YOUR CODE ###\n",
    "    # see slide 56\n",
    "    n, m = X.shape\n",
    "    yhat = predict(w, b, X)\n",
    "    w = ((1/m) * np.sum((yhat - Y) * X))\n",
    "    b = (1/m) * np.sum(yhat - Y)\n",
    "    return w, b\n",
    "    ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see page 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def step_MSE(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Computes the update of the weights and bias - by using the mean square error cost. \n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (1,n)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (n, m)\n",
    "    Y -- label vector (1, m)\n",
    "\n",
    "    Returns:\n",
    "    gradJ -- dictionary with the gradient w.r.t. w (key \"dw\") and w.r.t. b (key \"db\")\n",
    "    \"\"\"\n",
    "    ### START YOUR CODE ###\n",
    "    n, m = X.shape\n",
    "    yhat = predict(w, b, X)\n",
    "    #w = w - b * np.dot((yhat - Y), X) \n",
    "    #b = b - b * np.sum(yhat - Y)\n",
    "    # Folien 40\n",
    "    w = ((1/m) * np.sum(yhat*(1 - yhat)*(yhat - Y) * X))\n",
    "    b = ((1/m) * np.sum(yhat*(1 - yhat)*(yhat - Y)))\n",
    "    return w, b\n",
    "\n",
    "    ### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Output Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def error_rate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Compute the error rate defined as the fraction of misclassified samples.\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights of shape (1,n)\n",
    "    b -- bias (scalar)\n",
    "    X -- data of size (n, m)\n",
    "    Y -- label vector (1, m)\n",
    "\n",
    "    Returns:\n",
    "    error_rate \n",
    "    \"\"\"\n",
    "    return np.sum(Y !=predict(w, b, X, round=True))/Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "PIXELS = (8,8)\n",
    "COLS = 5\n",
    "def plot_digits(X,Y,indices):\n",
    "    \"\"\"\n",
    "    Plots the digits in a mosaic with up to 8 columns\n",
    "\n",
    "    Arguments:\n",
    "    X -- data of size (1, 64)\n",
    "    Y -- label (a scalar)\n",
    "    indices -- list of indices    \n",
    "    \"\"\"\n",
    "    if len(indices)==0:\n",
    "        print(\"No images to show!\")\n",
    "        return\n",
    "    cols = min(COLS, len(indices))\n",
    "    rows = len(indices)/COLS+1\n",
    "    plt.figure(figsize=(20,4*rows))\n",
    "    for index, (image, label) in enumerate(zip(X.T[indices,:], Y.T[indices,:])):\n",
    "        plt.subplot(rows, cols, index+1)\n",
    "        plt.imshow(np.reshape(image, PIXELS), cmap=plt.cm.gray)\n",
    "        plt.title('Sample %i\\n Label %i\\n' % (indices[index],label), fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Optimize (Learn)\n",
    "\n",
    "#### Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_params(n, random=False):\n",
    "    \"\"\"\n",
    "    This function creates initial values:\n",
    "    * for w a vector of zeros of shape (1,n) [random=False] or a vector of normally distributed random values [random=True] \n",
    "    * for b set to 0.\n",
    "    \n",
    "    Argument:\n",
    "    n -- size of the w vector we want (number of features)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (1,n)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    if random:\n",
    "        w = np.random.randn(*(1,n))\n",
    "    else:\n",
    "        w = np.zeros((1,n))\n",
    "    b = 0.0\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def optimize(w, b, x_train, y_train, x_test, y_test, nepochs, alpha, cost_type=\"CE\"):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running (batch) gradient descent. It starts with the given \n",
    "    weights as initial values and then iteratively updates the parameters for nepochs number of times.\n",
    "    Returns the trained parameters values as dictionary (keys \"w\" and \"b\") and various quantities \n",
    "    collected during learning also as dictionary: cost on training and test set (\"cost_train\", \"cost_test\"), \n",
    "    error rate on training and test set (\"error_train\", \"error_test\"), learning speed as length of dw \n",
    "    multiplied by alpha with key \"step_w\" and absolute value of db with key \"step_b\".\n",
    "    The output is provided in form of dictionaries (basically, to avoid handling too many variable names in \n",
    "    functional calls).\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (1,n)\n",
    "    b -- bias, a scalar\n",
    "    x -- data of shape (n,m)\n",
    "    y -- true \"label\" vector (containing 0 or 1), of shape (1, m)\n",
    "    nepochs -- number of iterations of the optimization loop\n",
    "    alpha -- learning rate of the gradient descent update rule\n",
    "    cost_type -- cost function to use for the opimisation (CE: cross entropy, MSE: mean square error)\n",
    "    debug -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    learning_curves -- dictionary with various measures computed during the training useful for plotting \n",
    "    different learning curves.    \n",
    "    \"\"\"     \n",
    "    # The following lists are used for tracking the learning progress so that learning curves can be plotted.\n",
    "    # Append an according value in each epoch\n",
    "    epochs = []  # fill here the epoch id (the iteration index when looping over nepochs)\n",
    "    train_costs = [] # fill here the cost on the training set  \n",
    "    test_costs = [] # fill here the cost on the test set \n",
    "    train_errors = [] # fill here the error rate on the training set\n",
    "    test_errors = [] # fill here the error rate on the test set \n",
    "    stepsize_w = [] # fill here the lenght of the gradient of the weights vector multiplied with alpha (for the training set)\n",
    "    stepsize_b = [] # fill here the absolute value of derivative wr.t. the bias multiplied with alpha (for the training set)\n",
    "        \n",
    "    if cost_type==\"CE\":\n",
    "        step = step_CE #step_CE(w, b, X, Y) return w, b\n",
    "        cost = cost_CE #cost_CE(yhat, y) return cost\n",
    "    elif cost_type==\"MSE\":\n",
    "        step = step_MSE\n",
    "        cost = cost_MSE\n",
    "    else:\n",
    "        print(\"Cost type %s not supported.\"%cost_type)\n",
    "        return\n",
    "        \n",
    "    ### START YOUR CODE ###\n",
    "    for e in range(nepochs):\n",
    "        t_w, t_b = step(w, b, x_train, y_train)\n",
    "        w = w - alpha * t_w\n",
    "        b = b - alpha * t_b\n",
    "        epochs.append(e)\n",
    "        stepsize_w.append(alpha * t_w)\n",
    "        stepsize_b.append(alpha * t_b)\n",
    "        train_costs.append(cost(predict(w, b, x_train), y_train)) #predict(w, b, X, round=False):\n",
    "        test_costs.append(cost(predict(w, b, x_test), y_test))\n",
    "        print('--')\n",
    "        print('predict', predict(w, b, x_test))\n",
    "        print('cost', cost(predict(w, b, x_test), y_test))\n",
    "        print('--')\n",
    "        train_errors.append(error_rate(w, b, x_train, y_train))\n",
    "        test_errors.append(error_rate(w, b, x_test, y_test))\n",
    "    \n",
    "    ### END YOUR CODE ###\n",
    "    \n",
    "    params = {\"w\": w, \"b\": b}    \n",
    "    learning_curves = {}\n",
    "    learning_curves[\"epochs\"] = epochs\n",
    "    learning_curves[\"step_w\"] = stepsize_w\n",
    "    learning_curves[\"step_b\"] = stepsize_b\n",
    "    learning_curves[\"cost_train\"] = train_costs\n",
    "    learning_curves[\"cost_test\"] = test_costs\n",
    "    learning_curves[\"error_train\"] = train_errors\n",
    "    learning_curves[\"error_test\"] = test_errors\n",
    "        \n",
    "    print(\"Training error / cost : %6.4f / %6.4f\"%(train_errors[-1], train_costs[-1]))\n",
    "    print(\"Test error / cost : %6.4f / %6.4f\"%(test_errors[-1], test_costs[-1]))\n",
    "\n",
    "    return params, learning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Training for Specific Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# target digit\n",
    "target = 5 \n",
    "learning_rate = 0.5\n",
    "nepochs = 20\n",
    "X_train = x_train\n",
    "Y_train = y_train==target\n",
    "X_test = x_test\n",
    "Y_test = y_test==target\n",
    "w,b = initialize_params(8*8)\n",
    "params, learning_curves = \\\n",
    "    optimize(w, b, X_train, Y_train, X_test, Y_test, nepochs=nepochs, \\\n",
    "                                 alpha = learning_rate, cost_type=\"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Learning Curves\n",
    "\n",
    "Cost <br>\n",
    "Error Rate <br>\n",
    "Learning Speed (Lenght of Parameter Change)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(learning_curves[\"epochs\"], learning_curves[\"cost_train\"], label=\"train\")\n",
    "plt.semilogy(learning_curves[\"epochs\"], learning_curves[\"cost_test\"], label=\"test\")\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "xmax = learning_curves[\"epochs\"][-1]\n",
    "plt.axis([0,xmax,0.002,0.5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEMCAYAAADTfFGvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAE/FJREFUeJzt3X2wXHV9x/H3lxAJAQyQAAJBCZVBiFEgAVFbB3yICcqDxUZEplYZIlaq/qESxooP01asU+pQECbUiFbLgyCKGjVCoWgLIqGoQdAEjMMlSCCWAAoU47d/7ElcNrv37u9yz929m/drZuee/Z3fOfd7T07u556n30ZmIklSt7brdQGSpInF4JAkFTE4JElFDA5JUhGDQ5JUxOCQJBUxOCRJRQwOSVKRvg+OiDggIj4XEVf1uhZJUs3BERHLImJ9RKxqaV8QET+PiDURsWS4dWTmvZl5Wp11SpK6t33N678UuAD44uaGiJgEXAi8DhgCfhQR1wKTgE+2LP/OzFxfc42SpAK1Bkdm3hQR+7c0Hwmsycx7ASLicuCEzPwk8MbRfq+IWAwsBthpp53mvuhFLxrtqiRpm7Ry5cqHM3OPkfrVfcTRzr7AfU3vh4CXdeocEdOBvwcOi4izq4DZSmYuBZYCzJs3L2+77baxq1iStgER8atu+vUiOKJNW8chejNzA3BGfeVIkkr04q6qIWC/pvczgXU9qEOSNAq9CI4fAQdGxKyIeA5wMnBtD+qQJI1CraeqIuIy4GhgRkQMAR/NzM9FxJnAd2ncSbUsM+8co+93HHDcC1/4wrFYnaRtyNNPP83Q0BBPPvlkr0up3ZQpU5g5cyaTJ08e1fIxiJ8A6MVxSaV++ctfsssuuzB9+nQi2l2KHQyZyYYNG3jssceYNWvWM+ZFxMrMnDfSOvr+yXFJGg9PPvnkwIcGQEQwffr0Z3VkZXBIUmXQQ2OzZ/tzGhySpCIGhyT1gUceeYTPfvazxcsde+yxPPLIIzVU1NlABUdEHBcRSzdu3NjrUiSpSKfg2LRp07DLLV++nF133bWustoaqODIzG9k5uJp06b1uhRJKrJkyRLuueceDj30UI444giOOeYYTjnlFObMmQPAiSeeyNy5c5k9ezZLly7dstz+++/Pww8/zNq1azn44IM5/fTTmT17NvPnz+eJJ56opdZeDDkiSX3t49+4k5+te3RM13nIPs/lo8fN7jj/3HPPZdWqVdxxxx3ceOONvOENb2DVqlVbbpldtmwZu+++O0888QRHHHEEJ510EtOnT3/GOlavXs1ll13GJZdcwqJFi7j66qs59dRTx/TnAINDkvrSkUce+YznLM4//3yuueYaAO677z5Wr169VXDMmjWLQw89FIC5c+eydu3aWmozOCSpxXBHBuNlp5122jJ94403ct1113HzzTczdepUjj766LbPYeywww5bpidNmlTbqaqBusYhSRPVLrvswmOPPdZ23saNG9ltt92YOnUqd999N7fccss4V/dMA3XE4VhVkiaq6dOn88pXvpIXv/jF7Ljjjuy1115b5i1YsICLL76Yl7zkJRx00EEcddRRPazUsaokCYC77rqLgw8+uNdljJt2P69jVUmSamFwSJKKGBySpCIGhySpiMEhSSoyUMHhIIeSVL+BCg4HOZQ0UY12WHWAz3zmM/zud78b44o6G6jgkKSJaiIFx0A9OS5JE1XzsOqve93r2HPPPbnyyit56qmneNOb3sTHP/5xfvvb37Jo0SKGhobYtGkTH/nIR3jwwQdZt24dxxxzDDNmzOCGG26ovVaDQ5JafXsJ/PqnY7vO582Bhed2nN08rPqKFSu46qqruPXWW8lMjj/+eG666SYeeugh9tlnH771rW8BjTGspk2bxnnnnccNN9zAjBkzxrbmDjxVJUl9ZsWKFaxYsYLDDjuMww8/nLvvvpvVq1czZ84crrvuOs466yy+//3v06vruR5xSFKrYY4MxkNmcvbZZ/Oud71rq3krV65k+fLlnH322cyfP59zzjln3OvziEOS+kDzsOqvf/3rWbZsGY8//jgA999/P+vXr2fdunVMnTqVU089lQ984APcfvvtWy07HjzikKQ+0Dys+sKFCznllFN4+ctfDsDOO+/Ml770JdasWcMHP/hBtttuOyZPnsxFF10EwOLFi1m4cCF77733uFwcH6hh1Zs+j+P01atX97ocSROIw6pvo8Oq+wCgJNVvoIJDklQ/g0OSKoN06n44z/bnNDgkCZgyZQobNmwY+PDITDZs2MCUKVNGvQ7vqpIkYObMmQwNDfHQQw/1upTaTZkyhZkzZ456eYNDkoDJkycza9asXpcxIXiqSpJUxOCQJBUxOCRJRQwOSVKRgQoOP3Nckuo3UMHhkCOSVL+BCg5JUv0MDklSEYNDklTE4JAkFTE4JElFDA5JUhGDQ5JUxOCQJBUxOCRJRQwOSVIRg0OSVGSggsNBDiWpfgMVHA5yKEn1G6jgkCTVz+CQJBUxOCRJRQwOSVIRg0OSVMTgkCQVMTgkSUUMDklSEYNDklTE4JAkFTE4JElFDA5JUhGDQ5JUxOCQJBUxOCRJRQwOSVIRg0OSVGSggsOPjpWk+g1UcPjRsZJUv4EKDklS/QwOSVIRg0OSVMTgkCQVMTgkSUUMDklSEYNDklTE4JAkFTE4JElFDA5JUhGDQ5JUxOCQJBUxOCRJRQwOSVIRg0OSVMTgkCQVMTgkSUUMDklSEYNDklTE4JAkFTE4JElFRgyOiJgUEZ8ej2IkSf1vxODIzE3A3IiIcahHktTntu+y3/8AX4+IrwC/3dyYmV+tpSpJUt/qNjh2BzYAr25qS8DgkKRtTFfBkZnvqLsQSdLE0NVdVRExMyKuiYj1EfFgRFwdETPrLk6S1H+6vR3388C1wD7AvsA3qjZJ0jam2+DYIzM/n5m/r16XAnvUWNcWEXFiRFwSEV+PiPnj8T0lSZ11GxwPR8Sp1TMdkyLiVBoXy4cVEcuq01urWtoXRMTPI2JNRCwZbh2Z+bXMPB34K+AtXdYrSapJt8HxTmAR8GvgAeDNVdtILgUWNDdExCTgQmAhcAjw1og4JCLmRMQ3W157Ni36t9VykqQeGvGuquoX/UmZeXzpyjPzpojYv6X5SGBNZt5brf9y4ITM/CTwxjbfP4BzgW9n5u3D1LkYWAzw/Oc/v7RUSVKXun1y/IQx/J77Avc1vR+q2jr5G+C1wJsj4oxOnTJzaWbOy8x5e+wxLpdfJGmb1O0DgP8VERcAV/DMJ8c7HgEMo93QJdmpc2aeD5w/iu8jSapBt8HxiurrJ5rakmc+Sd6tIWC/pvczgXWjWI8kqQe6ucaxHXBRZl45Rt/zR8CBETELuB84GThljNYtSapZN9c4/gCcOZqVR8RlwM3AQRExFBGnZebvq/V9F7gLuDIz7xzN+tt8v+MiYunGjRvHYnWSpDYis+PlhT92ivgI8ARbX+P4TX2ljd68efPytttu63UZkjShRMTKzJw3Ur9ur3FsfmbjPU1tCRxQWpgkaWLrdnTcWXUXIkmaGIa9xhERH2qa/ouWef9QV1GSpP410sXxk5umz26ZtwBJ0jZnpOCIDtPt3vecd1VJUv1GCo7sMN3ufc9l5jcyc/G0adN6XYokDayRLo6/NCIepXF0sWM1TfV+Sq2VSZL60rDBkZmTxqsQSdLE0O3ncUiSBBgckqRCAxUc3lUlSfUbqODwripJqt9ABYckqX4GhySpiMEhSSpicEiSihgckqQiAxUc3o4rSfUbqODwdlxJqt9ABYckqX4GhySpiMEhSSpicEiSihgckqQiBockqYjBIUkqMlDB4QOAklS/gQoOHwCUpPoNVHBIkupncEiSihgckqQiBockqYjBIUkqYnBIkooYHJKkIgaHJKnIQAWHT45LUv0GKjh8clyS6jdQwSFJqp/BIUkqYnBIkooYHJKkIgaHJKmIwSFJKmJwSJKKGBySpCIGhySpiMEhSSpicEiSihgckqQiAxUcjo4rSfUbqOBwdFxJqt9ABYckqX4GhySpiMEhSSpicEiSihgckqQiBockqYjBIUkqYnBIkooYHJKkIgaHJKmIwSFJKmJwSJKKGBySpCIGhySpiMEhSSpicEiSihgckqQiAxUcfnSsJNVvoILDj46VpPoNVHBIkupncEiSihgckqQiBockqYjBIUkqYnBIkooYHJKkIgaHJKmIwSFJKmJwSJKKGBySpCIGhySpiMEhSSpicEiSihgckqQiBockqYjBIUkqYnBIkooYHJKkIgaHJKmIwSFJKmJwSJKKGBySpCIGhySpiMEhSSpicEiSihgckqQifR8cEXFwRFwcEVdFxLt7XY8kbetqDY6IWBYR6yNiVUv7goj4eUSsiYglw60jM+/KzDOARcC8OuuVJI2s7iOOS4EFzQ0RMQm4EFgIHAK8NSIOiYg5EfHNltee1TLHAz8Arq+5XknSCLavc+WZeVNE7N/SfCSwJjPvBYiIy4ETMvOTwBs7rOda4NqI+Bbw7/VVLEkaSa3B0cG+wH1N74eAl3XqHBFHA38O7AAsH6bfYmBx9fap1tNjfW4G8HCviyhgvfWy3npZb2cv6KZTL4Ij2rRlp86ZeSNw40grzcylwFKAiLgtMyfM9RDrrZf11st669WP9fbirqohYL+m9zOBdT2oQ5I0Cr0Ijh8BB0bErIh4DnAycG0P6pAkjULdt+NeBtwMHBQRQxFxWmb+HjgT+C5wF3BlZt45xt966Rivr27WWy/rrZf11qvv6o3MjpcXJEnaSt8/OS5J6i8GhySpyIQOjpGGLomIHSLiimr+D9s8jDhuImK/iLghIu6KiDsj4n1t+hwdERsj4o7qdU4vam2qZ21E/LSq5bY28yMizq+2708i4vBe1FnVclDTdrsjIh6NiPe39Onp9m03BE9E7B4R34uI1dXX3Tos+/aqz+qIeHsP6/10RNxd/XtfExG7dlh22H1nHOv9WETc3/RvfmyHZbseBqnmeq9oqnVtRNzRYdlx377PkJkT8gVMAu4BDgCeA/wYOKSlz18DF1fTJwNX9LDevYHDq+ldgF+0qfdo4Ju93rZN9awFZgwz/1jg2zSezTkK+GGva27aN34NvKCfti/wKuBwYFVT2z8CS6rpJcCn2iy3O3Bv9XW3anq3HtU7H9i+mv5Uu3q72XfGsd6PAR/oYn8Z9nfJeNXbMv+fgHP6Zfs2vybyEceWoUsy8/+Ay4ETWvqcAHyhmr4KeE1EtHsAsXaZ+UBm3l5NP0bjjrJ9e1HLGDoB+GI23ALsGhF797oo4DXAPZn5q14X0iwzbwJ+09LcvI9+ATixzaKvB76Xmb/JzP8FvkfLGHB1aFdvZq7Ixp2RALfQeA6rL3TYvt3o5nfJmBuu3ur31CLgsrrrGI2JHBzthi5p/UW8pU+1s28Epo9LdcOoTpkdBvywzeyXR8SPI+LbETF7XAvbWgIrImJlNaRLq27+DXrhZDr/h+un7QuwV2Y+AI0/LoA92/Tp1+38ThpHnO2MtO+MpzOrU2vLOpwK7Mft+2fAg5m5usP8nm7fiRwc3QxdUjS8yXiIiJ2Bq4H3Z+ajLbNvp3F65aXAvwBfG+/6WrwyMw+nMZLxeyLiVS3z+3H7Pgc4HvhKm9n9tn271Y/b+cPA74Evd+gy0r4zXi4C/gQ4FHiAxumfVn23fYG3MvzRRk+370QOjm6GLtnSJyK2B6YxukPZMRERk2mExpcz86ut8zPz0cx8vJpeDkyOiBnjXGZzPeuqr+uBa2gc0jfrx+FjFgK3Z+aDrTP6bftWHtx8eq/6ur5Nn77aztXF+TcCb8vqhHurLvadcZGZD2bmpsz8A3BJhzr6bftuT2Ng1ys69en19p3IwdHN0CXXApvvQHkz8B+ddvS6VecsPwfclZnndejzvM3XYCLiSBr/PhvGr8pn1LJTROyyeZrGRdHWEYevBf6yurvqKGDj5tMuPdTxL7V+2r5NmvfRtwNfb9Pnu8D8iNitOtUyv2obdxGxADgLOD4zf9ehTzf7zrhoueb2pg519NswSK8F7s7MoXYz+2L79uqq/Fi8aNzV8wsad0R8uGr7BI2dGmAKjVMWa4BbgQN6WOuf0jj8/QlwR/U6FjgDOKPqcyZwJ427Om4BXtHDeg+o6vhxVdPm7dtcb9D4UK57gJ8C83q8P0ylEQTTmtr6ZvvSCLQHgKdp/JV7Go1rbtcDq6uvu1d95wH/2rTsO6v9eA3wjh7Wu4bG9YDN+/Dmuxb3AZYPt+/0qN5/q/bNn9AIg71b663eb/W7pBf1Vu2Xbt5nm/r2fPs2vxxyRJJUZCKfqpIk9YDBIUkqYnBIkooYHJKkIgaHJKmIwSF1KSI2tYzAO2ajqEbE/s2jpEr9bPteFyBNIE9k5qG9LkLqNY84pGep+myET0XErdXrhVX7CyLi+mqAvesj4vlV+17VZ1n8uHq9olrVpIi4JBqf17IiInas+r83In5WrefyHv2Y0hYGh9S9HVtOVb2lad6jmXkkcAHwmartAhrDzr+ExmCA51ft5wP/mY3BFg+n8fQvwIHAhZk5G3gEOKlqXwIcVq3njLp+OKlbPjkudSkiHs/Mndu0rwVenZn3VgNZ/jozp0fEwzSGuHi6an8gM2dExEPAzMx8qmkd+9P4zI0Dq/dnAZMz8+8i4jvA4zRG8/1aVgM1Sr3iEYc0NrLDdKc+7TzVNL2JP16DfAONMcHmAiur0VOlnjE4pLHxlqavN1fT/01jpFWAtwE/qKavB94NEBGTIuK5nVYaEdsB+2XmDcCHgF2BrY56pPHkXy5S93aMiDua3n8nMzffkrtDRPyQxh9jb63a3gssi4gPAg8B76ja3wcsjYjTaBxZvJvGKKntTAK+FBHTaIxG/M+Z+ciY/UTSKHiNQ3qWqmsc8zLz4V7XIo0HT1VJkop4xCFJKuIRhySpiMEhSSpicEiSihgckqQiBockqcj/A5XiJuTfg2wzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(learning_curves[\"epochs\"], learning_curves[\"error_train\"], label=\"train\")\n",
    "plt.semilogy(learning_curves[\"epochs\"], learning_curves[\"error_test\"], label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epochs')\n",
    "xmax = learning_curves[\"epochs\"][-1]\n",
    "plt.axis([0,xmax,0.001,0.1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(learning_curves[\"epochs\"], learning_curves[\"step_w\"], label=\"w\")\n",
    "plt.semilogy(learning_curves[\"epochs\"], learning_curves[\"step_b\"], label=\"b\")\n",
    "plt.ylabel('Step Size')\n",
    "plt.xlabel('Epochs')\n",
    "xmax = learning_curves[\"epochs\"][-1]\n",
    "plt.axis([0,xmax,0.00001,0.2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "[  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  19\n",
      "  20  21  22  23  24  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  57\n",
      "  58  59  60  61  62  63  64  65  66  67  68  69  70  71  73  74  75  76\n",
      "  77  78  79  80  81  82  83  85  86  88  89  90  91  92  93  94  95  96\n",
      "  97  99 102 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
      " 120 122 123 124 125 126 127 128 130 131 132 134 135 137 139 140 141 142\n",
      " 143 144 145 147 149 150 151 153 154 155 156 157 158 159 160 161 162 164\n",
      " 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 182 183\n",
      " 184 185 186 187 188 189 190 192 193 194 195 196 197 198 199 201 202 203\n",
      " 204 205 206 207 208 209 211 212 213 214 215 216 217 218 219 220 221 222\n",
      " 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240\n",
      " 241 242 243 244 245 246 249 251 252 253 254 255 258 259 260 261 262 264\n",
      " 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282\n",
      " 284 285 287 288 289 290 291 292 294 295 296 297 298 299 300 301 302 303\n",
      " 304 305 306 307 308 309 310 311 312 313 315 316 317 318 319 320 321 322\n",
      " 323 324 325 327 328 329 330 331 332 334 335 336 337 338 339 341 342 343\n",
      " 345 346 347 348 349 350 351 352 353 354 356 357 358 359]\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False]]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "[[8.77482904e-10 6.28957949e-09 3.70688082e-10 3.52437148e-08\n",
      "  2.29069181e-08 1.06717233e-07 1.83656908e-09 1.12243586e-09\n",
      "  1.43576843e-09 5.36281637e-10 6.06532897e-10 1.31640709e-08\n",
      "  6.28957949e-09 5.91413036e-09 1.19369191e-09 7.11349522e-09\n",
      "  3.00505902e-09 3.27753388e-10 1.41997473e-11 3.11616357e-08\n",
      "  3.48560289e-10 2.49839358e-09 6.85986857e-10 2.75523605e-08\n",
      "  3.00505902e-09 9.33188506e-10 4.91698340e-09 4.91698340e-09\n",
      "  2.34925488e-09 1.20696863e-07 9.43567832e-08 8.34279740e-08\n",
      "  3.00505902e-09 6.68886341e-09 2.49839358e-09 8.04534140e-09\n",
      "  9.43567832e-08 2.26549385e-10 2.15395163e-08 4.34747715e-09\n",
      "  3.39871259e-09 1.52691590e-09 8.87242654e-08 1.83656908e-09\n",
      "  2.62777264e-11 1.02912315e-08 7.03524556e-11 9.33188506e-10\n",
      "  3.11616357e-08 5.04268929e-10 5.49992025e-11 3.52437148e-08\n",
      "  3.19583040e-09 3.00505902e-09 2.02537400e-08 8.55608706e-09\n",
      "  2.82567552e-09 3.98605338e-08 1.39997709e-08 5.56109323e-09\n",
      "  2.65700011e-09 1.79078644e-08 9.43567832e-08 7.48186690e-11\n",
      "  7.29535638e-10 8.46196865e-11 1.12243586e-09 5.36281637e-10\n",
      "  3.39871259e-09 2.82567552e-09 9.92430489e-10 1.12243586e-09\n",
      "  1.23782570e-08 5.42246416e-08 1.72693723e-09 1.39997709e-08\n",
      "  5.76670062e-08 1.39997709e-08 6.28957949e-09 3.61447443e-09\n",
      "  1.36507782e-07 1.56595250e-10 3.48560289e-10 5.42246416e-08\n",
      "  2.15395163e-08 1.00346872e-07 7.37649865e-08 7.11349522e-09\n",
      "  3.74811057e-08 3.52437148e-08 1.68388753e-08 1.36507782e-07\n",
      "  7.56508411e-09 5.22913025e-09 2.13025783e-10 1.58336982e-08\n",
      "  6.52212077e-08 9.09925659e-09 1.13492005e-07 2.65700011e-09\n",
      "  9.67690837e-09 5.17160891e-11 3.31398823e-08 1.58336982e-08\n",
      "  2.59076545e-08 3.08188531e-10 1.43576843e-09 1.23782570e-08\n",
      "  1.06717233e-07 1.01780262e-10 4.74167182e-10 2.82567552e-09\n",
      "  4.91698340e-09 6.61528476e-11 3.08188531e-10 1.05543335e-09\n",
      "  2.65700011e-09 9.43567832e-08 4.62346980e-09 3.52437148e-08\n",
      "  5.70326621e-10 1.16393514e-08 9.43567832e-08 6.06532897e-10\n",
      "  1.72693723e-09 1.66536449e-10 3.27753388e-10 2.43611272e-08\n",
      "  4.62346980e-09 1.22420941e-10 9.92430489e-10 7.75849044e-10\n",
      "  5.91413036e-09 5.04268929e-10 6.45037670e-10 1.33521099e-11\n",
      "  6.06532897e-10 3.98605338e-08 3.11616357e-08 1.28359110e-07\n",
      "  6.68886341e-09 1.85699603e-07 3.52437148e-08 8.77482904e-10\n",
      "  6.45037670e-10 1.16393514e-08 8.25102583e-10 2.65700011e-09\n",
      "  5.56109323e-09 4.23910161e-08 8.65124497e-07 4.74167182e-10\n",
      "  4.08795956e-09 6.28957949e-09 3.57471458e-11 3.11616357e-08\n",
      "  5.70326621e-10 2.40931511e-10 1.48885240e-08 9.33188506e-10\n",
      "  1.19369191e-09 1.15113166e-10 7.84478386e-08 1.23782570e-08\n",
      "  2.15395163e-08 1.79078644e-08 6.28957949e-09 2.34925488e-09\n",
      "  3.39871259e-09 1.36507782e-07 2.56226663e-10 5.04268929e-10\n",
      "  1.36507782e-07 4.62346980e-09 3.39871259e-09 5.09877648e-08\n",
      "  1.43576843e-09 6.52212077e-08 6.28957949e-09 4.08795956e-09\n",
      "  1.79078644e-08 1.39997709e-08 1.52691590e-09 2.29069181e-08\n",
      "  4.08795956e-09 1.16393514e-08 7.84478386e-08 5.91413036e-09\n",
      "  1.28359110e-07 9.33188506e-10 3.31398823e-08 9.92430489e-10\n",
      "  4.08795956e-09 1.48885240e-08 2.34925488e-09 6.06532897e-10\n",
      "  1.12243586e-09 1.52691590e-09 4.08795956e-09 1.00346872e-07\n",
      "  8.25102583e-10 2.07715403e-09 1.06717233e-07 3.11616357e-08\n",
      "  1.72693723e-09 5.04268929e-10 5.84907391e-11 5.36281637e-10\n",
      "  2.43611272e-08 6.85986857e-10 3.61447443e-09 2.34925488e-09\n",
      "  4.62346980e-09 9.33188506e-10 2.49839358e-09 5.42246416e-08\n",
      "  1.05543335e-09 2.34925488e-09 2.49839358e-09 1.20696863e-07\n",
      "  1.58336982e-08 4.23910161e-08 8.55608706e-09 4.74167182e-10\n",
      "  1.20696863e-07 7.56508411e-09 5.70326621e-10 1.43576843e-09\n",
      "  3.27753388e-10 6.45037670e-10 3.31398823e-08 3.39871259e-09\n",
      "  5.56109323e-09 5.70326621e-10 1.16393514e-08 9.33188506e-10\n",
      "  3.11616357e-08 3.08188531e-10 6.13279039e-08 1.13492005e-07\n",
      "  3.98605338e-08 1.83656908e-09 3.00505902e-09 5.36281637e-10\n",
      "  1.68388753e-08 4.79441097e-08 3.08188531e-10 1.09445539e-08\n",
      "  1.30192640e-10 6.28957949e-09 3.94220624e-10 1.02912315e-08\n",
      "  6.85986857e-10 8.55608706e-09 4.50821420e-08 2.34925488e-09\n",
      "  2.34925488e-09 4.74167182e-10 3.08188531e-10 1.20696863e-07\n",
      "  1.83656908e-09 9.09925659e-09 1.72693723e-09 1.00346872e-07\n",
      "  3.48560289e-10 3.94220624e-10 2.00309456e-10 6.13279039e-08\n",
      "  1.31640709e-08 5.04268929e-10 9.67690837e-09 5.09877648e-08\n",
      "  8.87242654e-08 7.37649865e-08 3.94220624e-10 7.75849044e-10\n",
      "  1.01780262e-10 1.39997709e-08 5.70326621e-10 1.47247479e-10\n",
      "  6.28957949e-09 4.62346980e-09 7.11349522e-09 2.65700011e-09\n",
      "  3.19583040e-09 3.39871259e-09 1.52691590e-09 3.08188531e-10\n",
      "  3.61447443e-09 8.87242654e-08 3.84393357e-09 1.28359110e-07\n",
      "  1.43576843e-09 6.28957949e-09 1.47247479e-10 8.87242654e-08\n",
      "  5.22913025e-09 2.93014781e-08 1.39997709e-08 1.79078644e-08\n",
      "  3.74811057e-08 3.84393357e-09 1.20696863e-07 5.56109323e-09\n",
      "  2.15395163e-08 9.92430489e-10 5.42246416e-08 8.55608706e-09\n",
      "  6.45037670e-10 1.52691590e-09 9.09925659e-09 3.39871259e-09\n",
      "  3.11616357e-08 2.26549385e-10 2.65700011e-09 4.50821420e-08\n",
      "  5.76670062e-08 3.00505902e-09 2.02537400e-08 7.11349522e-09]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = predict(params['w'], params['b'], X_test, round=True)\n",
    "indices = np.where(Y_test!=Y_pred)[1]\n",
    "print(len(indices))\n",
    "print(indices)\n",
    "print(Y_test[:,indices])\n",
    "print(Y_pred[:,indices])\n",
    "print(predict(params['w'], params['b'], X_test[:,indices]))\n",
    "\n",
    "plot_digits(x_test, y_test, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Trained Weights as 8x8 Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(params['w'], (8,8)), cmap=plt.cm.gray)\n",
    "np.set_printoptions(precision=3, formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print(np.reshape(params['w'], (8,8)))\n",
    "print(params['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis for all the Digits\n",
    "\n",
    "Run batch gradient descent independently for all the digits (0-9).<br>\n",
    "Plot the error rates (train and test) for the trained models against the digit in a single plot. <br>\n",
    "Which digit can be predicted very well - for which is the prediction rather bad? <br>\n",
    "Plot the digits and interpret what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
